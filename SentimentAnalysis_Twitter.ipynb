{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhakar-gh/Twitter-Sentiment-Analysis/blob/main/SentimentAnalysis_Twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis of Twitter Data using DistilBERT\n",
        "\n",
        "This project demonstrates the application of deep learning for sentiment analysis using the DistilBERT model. It focuses on classifying tweets into positive and negative sentiment categories. The project leverages the Hugging Face Transformers library for model implementation and the Kaggle API for accessing a large dataset of pre-processed tweets.\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "* **Data:** Utilizes a substantial dataset from Kaggle containing 1.6 million tweets labeled for sentiment.\n",
        "* **Model:** Employs the DistilBERT model, a smaller and faster variant of BERT, for efficient sentiment classification.\n",
        "* **Training:** Fine-tunes DistilBERT using the training dataset to adapt it specifically for sentiment analysis.\n",
        "* **Evaluation:** Assesses the model's performance using metrics like accuracy and F1-score.\n",
        "* **Deployment:** Provides a simple UI using Gradio for real-time sentiment prediction.\n",
        "\n",
        "This project was developed as a personal exploration of natural language processing and deep learning techniques for sentiment analysis."
      ],
      "metadata": {
        "id": "o0IipzizGbmf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eazIyCMwxnoY"
      },
      "source": [
        "#Setup\n",
        "Install all the necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_Hwsj76FUS2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch pandas sklearn\n",
        "!pip install gradio --upgrade  # Optional, for UI demo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Kaggle Integration\n",
        "This section sets up access to Kaggle datasets within Google Colab.\n",
        "- You'll be prompted to upload your `kaggle.json` file, containing your Kaggle API credentials.\n",
        "- The code creates the necessary Kaggle directory and moves the `kaggle.json` file into it.\n",
        "- File permissions are set for security.\n",
        "- Kaggle access is verified by listing available datasets.\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6bB8FeTEBU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s48QSgpw60Mk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading the Dataset\n",
        "This section downloads the sentiment analysis dataset from Kaggle using the `kagglehub` library.\n",
        "- It stores the path to the downloaded dataset files.\n",
        "- The full path to the dataset file is defined for later use."
      ],
      "metadata": {
        "id": "PP5dqHwbEN91"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS26iWoqsLc8"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ferno2/training1600000processednoemoticoncsv\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ6uwv8xsdIS"
      },
      "outputs": [],
      "source": [
        "DATAFILE=path+\"/training.1600000.processed.noemoticon.csv\"\n",
        "print (DATAFILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing\n",
        "This section loads the dataset into a pandas DataFrame and preprocesses it:\n",
        "- It reads the CSV file, specifying the encoding and column names.\n",
        "- Target labels are mapped to 0 (negative) and 1 (positive).\n",
        "- A smaller sample of the dataset is taken for faster training (5k positive, 5k negative).\n",
        "- Only the relevant columns ('text' and 'target') are kept.\n",
        "- The head of the DataFrame is printed for a preview."
      ],
      "metadata": {
        "id": "QQMak6BeEcHA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz0SXxGes7if"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttN_si_QYd-q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(DATAFILE, encoding='latin-1',\n",
        "                 names=['target', 'id', 'date', 'flag', 'user', 'text'])\n",
        "\n",
        "# Map target: 0 (negative) -> 0, 4 (positive) -> 1\n",
        "df['target'] = df['target'].map({0: 0, 4: 1})\n",
        "\n",
        "# Sample 10k rows (5k positive, 5k negative)\n",
        "df = df.groupby('target').sample(n=5000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Keep only relevant columns\n",
        "df = df[['text', 'target']]\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Distribution of Sentiment\n",
        "This creates a bar chart showing the number of positive and negative tweets in your dataset. The plot is saved as 'sentiment_distribution.png'.\n"
      ],
      "metadata": {
        "id": "cS9nzpY-JW5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize the data set\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "sns.countplot(x='target', data=df)\n",
        "plt.title('Distribution of Sentiment')\n",
        "plt.xlabel('Sentiment (0: Negative, 1: Positive)')\n",
        "plt.ylabel('Count')\n",
        "plt.savefig('sentiment_distribution.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2TDS2aQoI-t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word Cloud\n",
        "This generates word clouds for positive and negative tweets, saved as 'positive_wordcloud.png' and 'negative_wordcloud.png' respectively.\n"
      ],
      "metadata": {
        "id": "ixWqeO9xJr4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "positive_words = ' '.join(df[df['target'] == 1]['text'].astype(str))\n",
        "negative_words = ' '.join(df[df['target'] == 0]['text'].astype(str))\n",
        "\n",
        "wordcloud_positive = WordCloud(width=800, height=500, background_color='white', stopwords=STOPWORDS).generate(positive_words)\n",
        "wordcloud_negative = WordCloud(width=800, height=500, background_color='white', stopwords=STOPWORDS).generate(negative_words)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title('Positive Word Cloud')\n",
        "plt.savefig('positive_wordcloud.png')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title('Negative Word Cloud')\n",
        "plt.savefig('negative_wordcloud.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ubOWuHsKMFsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting\n",
        "This section splits the data into training and testing sets using `train_test_split` from scikit-learn:\n",
        "- 80% of the data is used for training, and 20% for testing.\n",
        "- A random state is set for reproducibility."
      ],
      "metadata": {
        "id": "wl-tvQO8EinP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nygughu6Yime"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization and Dataset Preparation\n",
        "This section tokenizes the text data and prepares it for the model:\n",
        "- The `datasets` library is installed if needed.\n",
        "- A DistilBERT tokenizer is loaded from Hugging Face Transformers.\n",
        "- A function is defined to tokenize the text data, padding and truncating as necessary.\n",
        "- Pandas DataFrames are converted to Hugging Face Datasets.\n",
        "- The datasets are tokenized using the defined function.\n",
        "- The 'target' column is renamed to 'labels' and the format is set for PyTorch.\\"
      ],
      "metadata": {
        "id": "eZXSVoqIEpbC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI-BpLLycqnz"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5EpBJ3zYoll"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Tokenize\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Rename 'target' to 'labels' and format for PyTorch\n",
        "train_dataset = train_dataset.rename_column(\"target\", \"labels\")\n",
        "test_dataset = test_dataset.rename_column(\"target\", \"labels\")\n",
        "\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "This section defines and trains the sentiment analysis model:\n",
        "- A pre-trained DistilBERT model for sequence classification is loaded.\n",
        "- Training arguments are defined, including output directory, epochs, batch size, etc.\n",
        "- A `Trainer` instance is created using the model, arguments, and datasets.\n",
        "- The model is trained using `trainer.train()`.\\"
      ],
      "metadata": {
        "id": "PMAYQTutEvXd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY9yJ0EDYr28"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoxZ7bovYunL"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,  # 1 epoch to save time\n",
        "    per_device_train_batch_size=8,  # Small batch size for free tier\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\" #disabling wandb integration\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv7EEHheBTJG"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation\n",
        "This section evaluates the trained model's performance using `trainer.evaluate()`:\n",
        "- The evaluation results are printed."
      ],
      "metadata": {
        "id": "OPrKz5V7E5cB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute models F-1 score"
      ],
      "metadata": {
        "id": "BIZ_QbYQ6Gt5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flirS9cgY0qB"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = predictions.predictions.argmax(-1)  # Get predicted labels\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(predictions.label_ids, predicted_labels)  # Compare to true labels\n",
        "\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "KnixD_wn5AUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Saving\n",
        "This section saves the trained model and tokenizer for later use using `save_pretrained()`:\n",
        "- The model is saved to the 'sentiment_model' directory.\n",
        "- The tokenizer is saved to the same directory."
      ],
      "metadata": {
        "id": "sA8X4_9DE-ye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZrFcAamY4MR"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('sentiment_model')\n",
        "tokenizer.save_pretrained('sentiment_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix\n",
        "This generates a confusion matrix plot and saves it as 'confusion_matrix.png'.\n",
        "\n"
      ],
      "metadata": {
        "id": "jJkEsQruK5F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = predictions.predictions.argmax(-1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
        "disp.plot()\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R-Idqj5wKw8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Prediction\n",
        "This section demonstrates how to use the trained model for sentiment prediction:\n",
        "- A sentiment analysis pipeline is created using the trained model and tokenizer.\n",
        "- The pipeline is tested with an example text.\n",
        "- A function is defined to predict sentiment and format the output.\n",
        "- The prediction function is tested with another example."
      ],
      "metadata": {
        "id": "U8E7tFYrFF1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zi1EST0Y7X_"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sentiment_classifier = pipeline('sentiment-analysis', model='sentiment_model', tokenizer='sentiment_model')\n",
        "\n",
        "# Test it\n",
        "text = \"I love this product!\"\n",
        "result = sentiment_classifier(text)\n",
        "print(result)  # Outputs [{'label': 'LABEL_1', 'score': 0.95}] (1 = positive)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sH9VHNDJGYst"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YXuCKkyY-eH"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "    result = sentiment_classifier(text)[0]\n",
        "    label = 'Positive' if result['label'] == 'LABEL_1' else 'Negative'\n",
        "    return f\"{label} (confidence: {result['score']:.2f})\"\n",
        "\n",
        "print(predict_sentiment(\"I hate this weather\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio UI\n",
        "This section creates a simple UI using Gradio for interactive sentiment prediction:\n",
        "- Gradio is installed or upgraded if needed.\n",
        "- A function is defined for Gradio to use for prediction.\n",
        "- A Gradio interface is created and launched."
      ],
      "metadata": {
        "id": "TCOWu9TcFdpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --upgrade"
      ],
      "metadata": {
        "id": "P1_aoYjOcGE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDBwiLy_ZBUm"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def gradio_predict(text):\n",
        "    return predict_sentiment(text)\n",
        "\n",
        "interface = gr.Interface(fn=gradio_predict, inputs=\"text\", outputs=\"text\")\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH7YUfZ9ZELt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Packaging\n",
        "This section packages the trained model for sharing or deployment:\n",
        "- The 'sentiment_model' directory is zipped into an archive."
      ],
      "metadata": {
        "id": "5t3o_YEaFkOP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1Konp6IZESZ"
      },
      "outputs": [],
      "source": [
        "!zip -r sentiment_model.zip sentiment_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A5WfciT1tAtv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkyI2KFd2TxpjO008tNw2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}